from transformers import AutoTokenizer

def test_models():
    models = [
        "SherifAnar/russian-bpe-16k",
        "SherifAnar/russian-unigram-20k"
    ]

    for model_name in models:
        print(f"\nüîç –¢–µ—Å—Ç–∏—Ä—É–µ–º {model_name}:")
        
        try:
            tokenizer = AutoTokenizer.from_pretrained(model_name)
            text = "–ü—Ä–∏–≤–µ—Ç, –∫–∞–∫ –¥–µ–ª–∞?"
            tokens = tokenizer.tokenize(text)
            print(f"‚úÖ –†–∞–±–æ—Ç–∞–µ—Ç: '{text}' ‚Üí {tokens}")
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞: {e}")

if __name__ == "__main__":
    test_models()